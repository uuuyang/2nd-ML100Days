{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 請結合前面的知識與程式碼，比較不同的 optimizer 與 learning rate 組合對訓練的結果與影響\n",
    "### 常見的 optimizer 包含\n",
    "* SGD\n",
    "* RMSprop\n",
    "* AdaGrad\n",
    "* Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uyang\\Anaconda3\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[1024, 512, 256, 128, 64, 32]):\n",
    "    \"\"\"\n",
    "    Build your own model\n",
    "    \"\"\"\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "\"\"\"\n",
    "Set your required experiment parameters\n",
    "\"\"\"\n",
    "LEARNING_RATE = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "OPTIMIZERS = [keras.optimizers.SGD, keras.optimizers.RMSprop, keras.optimizers.Adagrad, keras.optimizers.Adam]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with LR = 0.100000\n",
      "Experiment with opt = <class 'keras.optimizers.SGD'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 2.0981 - acc: 0.2315 - val_loss: 1.9573 - val_acc: 0.2938\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.8932 - acc: 0.3167 - val_loss: 2.1403 - val_acc: 0.2728\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 1.7873 - acc: 0.3564 - val_loss: 2.0369 - val_acc: 0.2808\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.7320 - acc: 0.3829 - val_loss: 1.7219 - val_acc: 0.3677\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.6681 - acc: 0.4021 - val_loss: 1.7604 - val_acc: 0.3608\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.6244 - acc: 0.4188 - val_loss: 1.7657 - val_acc: 0.3689\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 1.5840 - acc: 0.4358 - val_loss: 1.6009 - val_acc: 0.4320\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.5656 - acc: 0.4417 - val_loss: 1.7380 - val_acc: 0.3847\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.5310 - acc: 0.4534 - val_loss: 1.6996 - val_acc: 0.3964\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.5022 - acc: 0.4640 - val_loss: 1.5263 - val_acc: 0.4443\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 1.4675 - acc: 0.4781 - val_loss: 1.6702 - val_acc: 0.4162\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 1.4430 - acc: 0.4839 - val_loss: 1.5642 - val_acc: 0.4397\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.4318 - acc: 0.4895 - val_loss: 1.8910 - val_acc: 0.3730\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 1.3870 - acc: 0.5062 - val_loss: 1.6402 - val_acc: 0.4271\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.3620 - acc: 0.5128 - val_loss: 1.4916 - val_acc: 0.4726\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.3309 - acc: 0.5250 - val_loss: 1.5778 - val_acc: 0.4464\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.3147 - acc: 0.5324 - val_loss: 1.8006 - val_acc: 0.4098\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.2974 - acc: 0.5368 - val_loss: 1.5341 - val_acc: 0.4598\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.2659 - acc: 0.5513 - val_loss: 1.6920 - val_acc: 0.4070\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.2421 - acc: 0.5566 - val_loss: 2.2612 - val_acc: 0.3289\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.2652 - acc: 0.5523 - val_loss: 1.6705 - val_acc: 0.4196\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.1988 - acc: 0.5753 - val_loss: 1.6423 - val_acc: 0.4350\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.1830 - acc: 0.5803 - val_loss: 1.5317 - val_acc: 0.4614\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 1.1589 - acc: 0.5840 - val_loss: 1.8016 - val_acc: 0.3899\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.1286 - acc: 0.5985 - val_loss: 1.6484 - val_acc: 0.4277\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.1089 - acc: 0.6058 - val_loss: 1.5773 - val_acc: 0.4641\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.0856 - acc: 0.6148 - val_loss: 1.5707 - val_acc: 0.4836\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.0633 - acc: 0.6228 - val_loss: 1.6168 - val_acc: 0.4485\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.0393 - acc: 0.6268 - val_loss: 1.5518 - val_acc: 0.4788\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.0162 - acc: 0.6372 - val_loss: 1.6188 - val_acc: 0.4537\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.9942 - acc: 0.6466 - val_loss: 1.5358 - val_acc: 0.4838\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.9614 - acc: 0.6588 - val_loss: 1.8238 - val_acc: 0.4319\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.9526 - acc: 0.6604 - val_loss: 1.5492 - val_acc: 0.4880\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.9168 - acc: 0.6751 - val_loss: 1.6185 - val_acc: 0.4821\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.8970 - acc: 0.6812 - val_loss: 1.6690 - val_acc: 0.4748\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.8672 - acc: 0.6937 - val_loss: 1.7403 - val_acc: 0.4793\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.8443 - acc: 0.6993 - val_loss: 1.7511 - val_acc: 0.4760\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.8359 - acc: 0.7049 - val_loss: 1.7986 - val_acc: 0.4597\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.8141 - acc: 0.7113 - val_loss: 1.7983 - val_acc: 0.4526\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.7795 - acc: 0.7245 - val_loss: 1.8169 - val_acc: 0.4702\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.7509 - acc: 0.7342 - val_loss: 1.8990 - val_acc: 0.4629\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.7237 - acc: 0.7436 - val_loss: 1.8855 - val_acc: 0.4728\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.7114 - acc: 0.7499 - val_loss: 1.7638 - val_acc: 0.4978\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.6937 - acc: 0.7530 - val_loss: 1.7527 - val_acc: 0.4980\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.6614 - acc: 0.7636 - val_loss: 1.9143 - val_acc: 0.4975\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.6613 - acc: 0.7676 - val_loss: 1.9040 - val_acc: 0.4857\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.6124 - acc: 0.7843 - val_loss: 1.8217 - val_acc: 0.4911\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.5976 - acc: 0.7896 - val_loss: 2.2340 - val_acc: 0.4340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.6062 - acc: 0.7860 - val_loss: 2.4955 - val_acc: 0.4107\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.5594 - acc: 0.8029 - val_loss: 2.1424 - val_acc: 0.4831\n",
      "Experiment with LR = 0.100000\n",
      "Experiment with opt = <class 'keras.optimizers.RMSprop'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 14.4453 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 13s 256us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 12s 245us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 12s 245us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 12s 240us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 13s 252us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 13s 252us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 12s 250us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 12s 239us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Experiment with LR = 0.100000\n",
      "Experiment with opt = <class 'keras.optimizers.Adagrad'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 14.4433 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Experiment with LR = 0.100000\n",
      "Experiment with opt = <class 'keras.optimizers.Adam'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 14s 287us/step - loss: 14.4427 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 14s 275us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 14s 274us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 14s 274us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 14s 276us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Experiment with LR = 0.010000\n",
      "Experiment with opt = <class 'keras.optimizers.SGD'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.1492 - acc: 0.2116 - val_loss: 2.2639 - val_acc: 0.1706\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.9831 - acc: 0.2849 - val_loss: 1.9662 - val_acc: 0.2776\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.8896 - acc: 0.3250 - val_loss: 1.9208 - val_acc: 0.3161\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.8226 - acc: 0.3492 - val_loss: 2.0513 - val_acc: 0.2948\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.7697 - acc: 0.3683 - val_loss: 1.7497 - val_acc: 0.3754\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.7319 - acc: 0.3811 - val_loss: 1.8629 - val_acc: 0.3469\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.6957 - acc: 0.3954 - val_loss: 1.8274 - val_acc: 0.3452\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.6677 - acc: 0.4073 - val_loss: 1.7153 - val_acc: 0.3863\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.6369 - acc: 0.4173 - val_loss: 1.6374 - val_acc: 0.4192\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.6119 - acc: 0.4274 - val_loss: 1.7257 - val_acc: 0.3911\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.5942 - acc: 0.4338 - val_loss: 1.6684 - val_acc: 0.4020\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.5765 - acc: 0.4427 - val_loss: 1.5854 - val_acc: 0.4296\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.5492 - acc: 0.4501 - val_loss: 1.5704 - val_acc: 0.4383\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.5368 - acc: 0.4551 - val_loss: 1.6047 - val_acc: 0.4266\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.5090 - acc: 0.4660 - val_loss: 1.7253 - val_acc: 0.4084\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.4954 - acc: 0.4687 - val_loss: 1.5501 - val_acc: 0.4506\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.4845 - acc: 0.4739 - val_loss: 1.5188 - val_acc: 0.4571\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.4607 - acc: 0.4815 - val_loss: 1.6695 - val_acc: 0.4230\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.4501 - acc: 0.4838 - val_loss: 1.5556 - val_acc: 0.4402\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.4324 - acc: 0.4900 - val_loss: 1.4954 - val_acc: 0.4734\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.4174 - acc: 0.4964 - val_loss: 1.4911 - val_acc: 0.4714\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.4039 - acc: 0.5019 - val_loss: 1.4547 - val_acc: 0.4758\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.3893 - acc: 0.5056 - val_loss: 1.6160 - val_acc: 0.4113\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.3759 - acc: 0.5090 - val_loss: 1.4686 - val_acc: 0.4764\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.3633 - acc: 0.5147 - val_loss: 1.7636 - val_acc: 0.4036\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.3557 - acc: 0.5186 - val_loss: 1.5405 - val_acc: 0.4546\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 1.3377 - acc: 0.5237 - val_loss: 1.4916 - val_acc: 0.4749\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.3176 - acc: 0.5324 - val_loss: 1.4333 - val_acc: 0.4836\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.3129 - acc: 0.5317 - val_loss: 1.5366 - val_acc: 0.4563\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.2940 - acc: 0.5388 - val_loss: 1.5679 - val_acc: 0.4455\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 1.2813 - acc: 0.5437 - val_loss: 1.3944 - val_acc: 0.5029\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.2733 - acc: 0.5479 - val_loss: 1.5179 - val_acc: 0.4536\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.2562 - acc: 0.5552 - val_loss: 1.4571 - val_acc: 0.4890\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.2557 - acc: 0.5565 - val_loss: 1.4564 - val_acc: 0.4851\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.2430 - acc: 0.5548 - val_loss: 1.3761 - val_acc: 0.5116\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.2301 - acc: 0.5621 - val_loss: 1.4280 - val_acc: 0.4894\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.2105 - acc: 0.5703 - val_loss: 1.5305 - val_acc: 0.4549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.2041 - acc: 0.5707 - val_loss: 1.4853 - val_acc: 0.4798\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.1892 - acc: 0.5782 - val_loss: 1.4145 - val_acc: 0.5037\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 1.1799 - acc: 0.5815 - val_loss: 1.4003 - val_acc: 0.4998\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.1675 - acc: 0.5840 - val_loss: 1.4619 - val_acc: 0.4864\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.1624 - acc: 0.5888 - val_loss: 1.4902 - val_acc: 0.4834\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.1410 - acc: 0.5962 - val_loss: 1.5865 - val_acc: 0.4485\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.1342 - acc: 0.5972 - val_loss: 1.4049 - val_acc: 0.5058\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.1197 - acc: 0.6022 - val_loss: 1.4252 - val_acc: 0.5063\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.1116 - acc: 0.6069 - val_loss: 1.4699 - val_acc: 0.4837\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.1002 - acc: 0.6086 - val_loss: 1.3556 - val_acc: 0.5197\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.0913 - acc: 0.6133 - val_loss: 1.4295 - val_acc: 0.4971\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.0712 - acc: 0.6198 - val_loss: 1.3373 - val_acc: 0.5241\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.0644 - acc: 0.6225 - val_loss: 1.5323 - val_acc: 0.4761\n",
      "Experiment with LR = 0.010000\n",
      "Experiment with opt = <class 'keras.optimizers.RMSprop'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 12s 239us/step - loss: 14.4479 - acc: 0.0997 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 11s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 11s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 11s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 11s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Experiment with LR = 0.010000\n",
      "Experiment with opt = <class 'keras.optimizers.Adagrad'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 12.3336 - acc: 0.1036 - val_loss: 2.3460 - val_acc: 0.1068\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0963 - acc: 0.2209 - val_loss: 1.9504 - val_acc: 0.2777\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.8656 - acc: 0.3240 - val_loss: 1.8456 - val_acc: 0.3180\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.7575 - acc: 0.3643 - val_loss: 1.7162 - val_acc: 0.3828\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6889 - acc: 0.3901 - val_loss: 1.7011 - val_acc: 0.3869\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6384 - acc: 0.4118 - val_loss: 1.6255 - val_acc: 0.4141\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.5960 - acc: 0.4295 - val_loss: 1.6075 - val_acc: 0.4292\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.5586 - acc: 0.4429 - val_loss: 1.5901 - val_acc: 0.4328\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.5220 - acc: 0.4573 - val_loss: 1.5427 - val_acc: 0.4465\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.4866 - acc: 0.4703 - val_loss: 1.5748 - val_acc: 0.4324\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.4623 - acc: 0.4809 - val_loss: 1.5670 - val_acc: 0.4457\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.4347 - acc: 0.4878 - val_loss: 1.4999 - val_acc: 0.4675\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.4105 - acc: 0.4969 - val_loss: 1.5704 - val_acc: 0.4572\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.3829 - acc: 0.5080 - val_loss: 1.4946 - val_acc: 0.4809\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.3648 - acc: 0.5147 - val_loss: 1.4625 - val_acc: 0.4816\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.3413 - acc: 0.5244 - val_loss: 1.4661 - val_acc: 0.4809\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3196 - acc: 0.5315 - val_loss: 1.4531 - val_acc: 0.4871\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3019 - acc: 0.5391 - val_loss: 1.4403 - val_acc: 0.4968\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2797 - acc: 0.5468 - val_loss: 1.4327 - val_acc: 0.4915\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.2612 - acc: 0.5537 - val_loss: 1.4230 - val_acc: 0.5018\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 1.2428 - acc: 0.5593 - val_loss: 1.5006 - val_acc: 0.4694\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2240 - acc: 0.5691 - val_loss: 1.5285 - val_acc: 0.4664\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.2071 - acc: 0.5719 - val_loss: 1.4633 - val_acc: 0.4829\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.1868 - acc: 0.5805 - val_loss: 1.4678 - val_acc: 0.4955\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.1704 - acc: 0.5864 - val_loss: 1.4346 - val_acc: 0.5013\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.1510 - acc: 0.5937 - val_loss: 1.4247 - val_acc: 0.5029\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.1357 - acc: 0.5974 - val_loss: 1.4075 - val_acc: 0.5083\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.1164 - acc: 0.6050 - val_loss: 1.4546 - val_acc: 0.5031\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.1012 - acc: 0.6098 - val_loss: 1.4362 - val_acc: 0.5042\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.0821 - acc: 0.6156 - val_loss: 1.4016 - val_acc: 0.5161\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.0658 - acc: 0.6248 - val_loss: 1.5494 - val_acc: 0.4679\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.0535 - acc: 0.6273 - val_loss: 1.4963 - val_acc: 0.5022\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.0315 - acc: 0.6362 - val_loss: 1.4685 - val_acc: 0.5005\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.0186 - acc: 0.6397 - val_loss: 1.4441 - val_acc: 0.5096\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.9987 - acc: 0.6476 - val_loss: 1.4567 - val_acc: 0.5082\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.9843 - acc: 0.6522 - val_loss: 1.4766 - val_acc: 0.4986\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.9678 - acc: 0.6610 - val_loss: 1.5699 - val_acc: 0.4761\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.9515 - acc: 0.6650 - val_loss: 1.4599 - val_acc: 0.5126\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.9353 - acc: 0.6722 - val_loss: 1.4743 - val_acc: 0.5132\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.9234 - acc: 0.6747 - val_loss: 1.4568 - val_acc: 0.5178\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.9081 - acc: 0.6800 - val_loss: 1.5280 - val_acc: 0.5067\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.8897 - acc: 0.6886 - val_loss: 1.5679 - val_acc: 0.4952\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.8790 - acc: 0.6912 - val_loss: 1.6109 - val_acc: 0.4894\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.8593 - acc: 0.6991 - val_loss: 1.5075 - val_acc: 0.5097\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.8437 - acc: 0.7049 - val_loss: 1.5823 - val_acc: 0.4992\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.8266 - acc: 0.7107 - val_loss: 1.6574 - val_acc: 0.4845\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.8162 - acc: 0.7164 - val_loss: 1.5917 - val_acc: 0.5017\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.8016 - acc: 0.7213 - val_loss: 1.5742 - val_acc: 0.5125\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.7844 - acc: 0.7268 - val_loss: 1.6793 - val_acc: 0.4884\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.7724 - acc: 0.7330 - val_loss: 1.6461 - val_acc: 0.4993\n",
      "Experiment with LR = 0.010000\n",
      "Experiment with opt = <class 'keras.optimizers.Adam'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 14.4333 - acc: 0.1002 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 13s 262us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Experiment with LR = 0.001000\n",
      "Experiment with opt = <class 'keras.optimizers.SGD'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.2924 - acc: 0.1274 - val_loss: 2.2802 - val_acc: 0.1449\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 2.2701 - acc: 0.1620 - val_loss: 2.2613 - val_acc: 0.1679\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2511 - acc: 0.1753 - val_loss: 2.2424 - val_acc: 0.1773\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2316 - acc: 0.1834 - val_loss: 2.2230 - val_acc: 0.1835\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.2113 - acc: 0.1900 - val_loss: 2.2021 - val_acc: 0.1944\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.1894 - acc: 0.1998 - val_loss: 2.1791 - val_acc: 0.2012\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.1650 - acc: 0.2092 - val_loss: 2.1541 - val_acc: 0.2131\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.1389 - acc: 0.2219 - val_loss: 2.1281 - val_acc: 0.2223\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.1117 - acc: 0.2336 - val_loss: 2.1005 - val_acc: 0.2421\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.0840 - acc: 0.2486 - val_loss: 2.0734 - val_acc: 0.2553\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.0569 - acc: 0.2597 - val_loss: 2.0476 - val_acc: 0.2709\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.0312 - acc: 0.2708 - val_loss: 2.0222 - val_acc: 0.2781\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.0073 - acc: 0.2787 - val_loss: 1.9992 - val_acc: 0.2842\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.9853 - acc: 0.2861 - val_loss: 1.9791 - val_acc: 0.2873\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.9658 - acc: 0.2923 - val_loss: 1.9601 - val_acc: 0.2963\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.9476 - acc: 0.2992 - val_loss: 1.9462 - val_acc: 0.3000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.9309 - acc: 0.3064 - val_loss: 1.9271 - val_acc: 0.3111\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.9153 - acc: 0.3127 - val_loss: 1.9144 - val_acc: 0.3122\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.9007 - acc: 0.3213 - val_loss: 1.9021 - val_acc: 0.3202\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.8866 - acc: 0.3301 - val_loss: 1.8844 - val_acc: 0.3289\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.8741 - acc: 0.3346 - val_loss: 1.8714 - val_acc: 0.3351\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.8618 - acc: 0.3406 - val_loss: 1.8609 - val_acc: 0.3430\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.8505 - acc: 0.3462 - val_loss: 1.8494 - val_acc: 0.3490\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.8402 - acc: 0.3504 - val_loss: 1.8404 - val_acc: 0.3544\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.8300 - acc: 0.3562 - val_loss: 1.8282 - val_acc: 0.3516\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.8208 - acc: 0.3593 - val_loss: 1.8209 - val_acc: 0.3566\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.8118 - acc: 0.3626 - val_loss: 1.8100 - val_acc: 0.3608\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.8036 - acc: 0.3670 - val_loss: 1.8009 - val_acc: 0.3673\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.7950 - acc: 0.3696 - val_loss: 1.7977 - val_acc: 0.3636\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.7874 - acc: 0.3717 - val_loss: 1.7884 - val_acc: 0.3663\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.7804 - acc: 0.3749 - val_loss: 1.7804 - val_acc: 0.3766\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.7724 - acc: 0.3752 - val_loss: 1.7757 - val_acc: 0.3757\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.7664 - acc: 0.3776 - val_loss: 1.7685 - val_acc: 0.3783\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.7598 - acc: 0.3810 - val_loss: 1.7728 - val_acc: 0.3744\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.7532 - acc: 0.3830 - val_loss: 1.7538 - val_acc: 0.3805\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.7471 - acc: 0.3851 - val_loss: 1.7449 - val_acc: 0.3846\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.7408 - acc: 0.3862 - val_loss: 1.7493 - val_acc: 0.3853\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.7352 - acc: 0.3881 - val_loss: 1.7348 - val_acc: 0.3890\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.7296 - acc: 0.3904 - val_loss: 1.7288 - val_acc: 0.3904\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.7243 - acc: 0.3909 - val_loss: 1.7202 - val_acc: 0.3922\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.7190 - acc: 0.3956 - val_loss: 1.7272 - val_acc: 0.3926\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.7133 - acc: 0.3963 - val_loss: 1.7118 - val_acc: 0.3932\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.7078 - acc: 0.3978 - val_loss: 1.7116 - val_acc: 0.3989\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.7031 - acc: 0.3998 - val_loss: 1.7025 - val_acc: 0.3962\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.6977 - acc: 0.4008 - val_loss: 1.7008 - val_acc: 0.3983\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.6929 - acc: 0.4015 - val_loss: 1.6984 - val_acc: 0.4003\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.6879 - acc: 0.4045 - val_loss: 1.6880 - val_acc: 0.4031\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.6834 - acc: 0.4051 - val_loss: 1.6895 - val_acc: 0.4006\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.6788 - acc: 0.4077 - val_loss: 1.6918 - val_acc: 0.3997\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.6734 - acc: 0.4097 - val_loss: 1.6821 - val_acc: 0.4039\n",
      "Experiment with LR = 0.001000\n",
      "Experiment with opt = <class 'keras.optimizers.RMSprop'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 2.2572 - acc: 0.1575 - val_loss: 2.1608 - val_acc: 0.1771\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.9818 - acc: 0.2723 - val_loss: 2.0831 - val_acc: 0.2462\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.8643 - acc: 0.3258 - val_loss: 1.7524 - val_acc: 0.3666\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.7992 - acc: 0.3544 - val_loss: 1.7513 - val_acc: 0.3573\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.7339 - acc: 0.3805 - val_loss: 1.7045 - val_acc: 0.3821\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.6884 - acc: 0.3936 - val_loss: 1.7163 - val_acc: 0.3837\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.6442 - acc: 0.4138 - val_loss: 1.7204 - val_acc: 0.3811\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.6128 - acc: 0.4245 - val_loss: 1.5614 - val_acc: 0.4400\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.5686 - acc: 0.4405 - val_loss: 1.6028 - val_acc: 0.4338\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.5449 - acc: 0.4496 - val_loss: 1.6166 - val_acc: 0.4234\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.5055 - acc: 0.4589 - val_loss: 1.7176 - val_acc: 0.4169\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.4846 - acc: 0.4720 - val_loss: 1.6324 - val_acc: 0.4209\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4536 - acc: 0.4828 - val_loss: 1.5410 - val_acc: 0.4548\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4184 - acc: 0.4931 - val_loss: 1.5595 - val_acc: 0.4426\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.3932 - acc: 0.5018 - val_loss: 1.4679 - val_acc: 0.4822\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.3675 - acc: 0.5091 - val_loss: 1.4853 - val_acc: 0.4842\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.3428 - acc: 0.5195 - val_loss: 1.6452 - val_acc: 0.4298\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.3172 - acc: 0.5277 - val_loss: 1.7875 - val_acc: 0.3978\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.2964 - acc: 0.5338 - val_loss: 1.4676 - val_acc: 0.4948\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.2617 - acc: 0.5441 - val_loss: 1.5283 - val_acc: 0.4719\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.2396 - acc: 0.5549 - val_loss: 1.4648 - val_acc: 0.4934\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.2123 - acc: 0.5664 - val_loss: 1.7292 - val_acc: 0.4341\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.1883 - acc: 0.5737 - val_loss: 1.4765 - val_acc: 0.4882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.1615 - acc: 0.5811 - val_loss: 1.6936 - val_acc: 0.4470\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.1384 - acc: 0.5892 - val_loss: 1.4872 - val_acc: 0.5018\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.1093 - acc: 0.6003 - val_loss: 1.5587 - val_acc: 0.4911\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.0811 - acc: 0.6096 - val_loss: 1.4822 - val_acc: 0.5100\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.0537 - acc: 0.6193 - val_loss: 1.5594 - val_acc: 0.5013\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.0326 - acc: 0.6290 - val_loss: 1.5990 - val_acc: 0.4717\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.0074 - acc: 0.6322 - val_loss: 1.5879 - val_acc: 0.4975\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 0.9814 - acc: 0.6445 - val_loss: 1.7189 - val_acc: 0.4811\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.9601 - acc: 0.6528 - val_loss: 1.8497 - val_acc: 0.4700\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.9318 - acc: 0.6622 - val_loss: 1.7390 - val_acc: 0.4670\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.9068 - acc: 0.6702 - val_loss: 1.6425 - val_acc: 0.4934\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.8861 - acc: 0.6796 - val_loss: 1.8180 - val_acc: 0.4568\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.8646 - acc: 0.6880 - val_loss: 1.7705 - val_acc: 0.4932\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.8441 - acc: 0.6942 - val_loss: 1.8238 - val_acc: 0.4662\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.8270 - acc: 0.7001 - val_loss: 1.8103 - val_acc: 0.4754\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.8053 - acc: 0.7087 - val_loss: 1.9310 - val_acc: 0.4937\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.7843 - acc: 0.7174 - val_loss: 2.0802 - val_acc: 0.4860\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.7626 - acc: 0.7247 - val_loss: 1.9274 - val_acc: 0.4841\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 0.7440 - acc: 0.7306 - val_loss: 1.9038 - val_acc: 0.4959\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.7247 - acc: 0.7376 - val_loss: 2.0444 - val_acc: 0.4732\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.7056 - acc: 0.7441 - val_loss: 2.0230 - val_acc: 0.4780\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.6854 - acc: 0.7525 - val_loss: 2.0694 - val_acc: 0.4979\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.6712 - acc: 0.7581 - val_loss: 2.3000 - val_acc: 0.4902\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.6628 - acc: 0.7606 - val_loss: 2.0406 - val_acc: 0.4942\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.6390 - acc: 0.7726 - val_loss: 2.4113 - val_acc: 0.4685\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.6295 - acc: 0.7748 - val_loss: 2.2042 - val_acc: 0.5023\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.6091 - acc: 0.7811 - val_loss: 2.2208 - val_acc: 0.4490\n",
      "Experiment with LR = 0.001000\n",
      "Experiment with opt = <class 'keras.optimizers.Adagrad'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 2.1004 - acc: 0.2292 - val_loss: 1.9646 - val_acc: 0.2868\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.8827 - acc: 0.3271 - val_loss: 1.8186 - val_acc: 0.3510\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.7903 - acc: 0.3625 - val_loss: 1.7523 - val_acc: 0.3789\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.7304 - acc: 0.3846 - val_loss: 1.7003 - val_acc: 0.3912\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6867 - acc: 0.4005 - val_loss: 1.6906 - val_acc: 0.3958\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6466 - acc: 0.4154 - val_loss: 1.6776 - val_acc: 0.4001\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6154 - acc: 0.4256 - val_loss: 1.8095 - val_acc: 0.3594\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.5926 - acc: 0.4340 - val_loss: 1.6327 - val_acc: 0.4209\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.5707 - acc: 0.4432 - val_loss: 1.6780 - val_acc: 0.3942\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.5507 - acc: 0.4500 - val_loss: 1.5809 - val_acc: 0.4349\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.5310 - acc: 0.4561 - val_loss: 1.5434 - val_acc: 0.4506\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.5118 - acc: 0.4653 - val_loss: 1.5160 - val_acc: 0.4589\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.4956 - acc: 0.4723 - val_loss: 1.5280 - val_acc: 0.4565\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.4796 - acc: 0.4771 - val_loss: 1.5130 - val_acc: 0.4587\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.4691 - acc: 0.4800 - val_loss: 1.5047 - val_acc: 0.4669\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.4558 - acc: 0.4860 - val_loss: 1.5323 - val_acc: 0.4492\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 1.4438 - acc: 0.4911 - val_loss: 1.5969 - val_acc: 0.4384\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.4312 - acc: 0.4946 - val_loss: 1.4711 - val_acc: 0.4730\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.4177 - acc: 0.4995 - val_loss: 1.4673 - val_acc: 0.4750\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.4095 - acc: 0.5022 - val_loss: 1.4628 - val_acc: 0.4761\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3993 - acc: 0.5071 - val_loss: 1.4495 - val_acc: 0.4815\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3843 - acc: 0.5126 - val_loss: 1.4551 - val_acc: 0.4773\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.3767 - acc: 0.5163 - val_loss: 1.4940 - val_acc: 0.4655\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3697 - acc: 0.5168 - val_loss: 1.4233 - val_acc: 0.4914\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3605 - acc: 0.5208 - val_loss: 1.4588 - val_acc: 0.4809\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3523 - acc: 0.5229 - val_loss: 1.4132 - val_acc: 0.4960\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3424 - acc: 0.5276 - val_loss: 1.4551 - val_acc: 0.4835\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3342 - acc: 0.5305 - val_loss: 1.6056 - val_acc: 0.4526\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.3290 - acc: 0.5308 - val_loss: 1.4286 - val_acc: 0.4917\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.3199 - acc: 0.5359 - val_loss: 1.4169 - val_acc: 0.4884\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3116 - acc: 0.5366 - val_loss: 1.4239 - val_acc: 0.4958\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3050 - acc: 0.5411 - val_loss: 1.3915 - val_acc: 0.5056\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2976 - acc: 0.5437 - val_loss: 1.3809 - val_acc: 0.5094\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2907 - acc: 0.5452 - val_loss: 1.3768 - val_acc: 0.5106\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.2845 - acc: 0.5468 - val_loss: 1.4055 - val_acc: 0.5001\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2770 - acc: 0.5504 - val_loss: 1.4256 - val_acc: 0.4919\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.2702 - acc: 0.5537 - val_loss: 1.4355 - val_acc: 0.4882\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.2632 - acc: 0.5556 - val_loss: 1.3923 - val_acc: 0.4984\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2564 - acc: 0.5594 - val_loss: 1.4070 - val_acc: 0.4918\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2499 - acc: 0.5614 - val_loss: 1.3960 - val_acc: 0.5061\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.2447 - acc: 0.5622 - val_loss: 1.3683 - val_acc: 0.5123\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2412 - acc: 0.5623 - val_loss: 1.3543 - val_acc: 0.5134\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2321 - acc: 0.5667 - val_loss: 1.3550 - val_acc: 0.5186\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.2263 - acc: 0.5688 - val_loss: 1.4036 - val_acc: 0.5005\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.2209 - acc: 0.5710 - val_loss: 1.3589 - val_acc: 0.5190\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2165 - acc: 0.5713 - val_loss: 1.4002 - val_acc: 0.5010\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2076 - acc: 0.5749 - val_loss: 1.3720 - val_acc: 0.5139\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.2025 - acc: 0.5765 - val_loss: 1.3553 - val_acc: 0.5238\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.1981 - acc: 0.5790 - val_loss: 1.3528 - val_acc: 0.5198\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.1937 - acc: 0.5800 - val_loss: 1.3554 - val_acc: 0.5158\n",
      "Experiment with LR = 0.001000\n",
      "Experiment with opt = <class 'keras.optimizers.Adam'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 2.0403 - acc: 0.2295 - val_loss: 1.9022 - val_acc: 0.2999\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.8073 - acc: 0.3437 - val_loss: 1.7248 - val_acc: 0.3729\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.6961 - acc: 0.3855 - val_loss: 1.6564 - val_acc: 0.3924\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.6141 - acc: 0.4198 - val_loss: 1.5843 - val_acc: 0.4355\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.5583 - acc: 0.4415 - val_loss: 1.5640 - val_acc: 0.4497\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.5081 - acc: 0.4594 - val_loss: 1.5482 - val_acc: 0.4466\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4730 - acc: 0.4718 - val_loss: 1.4819 - val_acc: 0.4706\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4413 - acc: 0.4826 - val_loss: 1.4694 - val_acc: 0.4777\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.4043 - acc: 0.4961 - val_loss: 1.4253 - val_acc: 0.4915\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3751 - acc: 0.5051 - val_loss: 1.4874 - val_acc: 0.4788\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3495 - acc: 0.5176 - val_loss: 1.4121 - val_acc: 0.4939\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3187 - acc: 0.5285 - val_loss: 1.4277 - val_acc: 0.4855\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.2884 - acc: 0.5385 - val_loss: 1.4160 - val_acc: 0.4973\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.2642 - acc: 0.5478 - val_loss: 1.3815 - val_acc: 0.5175\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.2275 - acc: 0.5591 - val_loss: 1.3849 - val_acc: 0.5085\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.1907 - acc: 0.5725 - val_loss: 1.3866 - val_acc: 0.5107\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.1783 - acc: 0.5780 - val_loss: 1.3705 - val_acc: 0.5193\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.1511 - acc: 0.5875 - val_loss: 1.3639 - val_acc: 0.5180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.1152 - acc: 0.6021 - val_loss: 1.3564 - val_acc: 0.5266\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.0965 - acc: 0.6061 - val_loss: 1.3910 - val_acc: 0.5144\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.0686 - acc: 0.6176 - val_loss: 1.4333 - val_acc: 0.5096\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.0380 - acc: 0.6271 - val_loss: 1.4277 - val_acc: 0.5142\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.0207 - acc: 0.6338 - val_loss: 1.3842 - val_acc: 0.5203\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.9851 - acc: 0.6465 - val_loss: 1.4607 - val_acc: 0.5126\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.9576 - acc: 0.6548 - val_loss: 1.4010 - val_acc: 0.5265\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.9469 - acc: 0.6607 - val_loss: 1.4269 - val_acc: 0.5242\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.9141 - acc: 0.6713 - val_loss: 1.4337 - val_acc: 0.5235\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.8871 - acc: 0.6829 - val_loss: 1.4722 - val_acc: 0.5209\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.8471 - acc: 0.6949 - val_loss: 1.5337 - val_acc: 0.5193\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.8271 - acc: 0.7028 - val_loss: 1.4922 - val_acc: 0.5272\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.8096 - acc: 0.7085 - val_loss: 1.5456 - val_acc: 0.5145\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.7848 - acc: 0.7174 - val_loss: 1.6354 - val_acc: 0.5121\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.7489 - acc: 0.7316 - val_loss: 1.5928 - val_acc: 0.5238\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.7333 - acc: 0.7359 - val_loss: 1.6262 - val_acc: 0.5142\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.6985 - acc: 0.7500 - val_loss: 1.7077 - val_acc: 0.5179\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.6779 - acc: 0.7579 - val_loss: 1.6774 - val_acc: 0.5209\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.6531 - acc: 0.7650 - val_loss: 1.7479 - val_acc: 0.5143\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.6328 - acc: 0.7734 - val_loss: 1.8027 - val_acc: 0.5121\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.6192 - acc: 0.7789 - val_loss: 1.8451 - val_acc: 0.5201\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.5849 - acc: 0.7903 - val_loss: 1.9675 - val_acc: 0.5074\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.5760 - acc: 0.7937 - val_loss: 1.8848 - val_acc: 0.5154\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.5423 - acc: 0.8046 - val_loss: 1.9191 - val_acc: 0.5144\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.5488 - acc: 0.8023 - val_loss: 1.9860 - val_acc: 0.5193\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.5392 - acc: 0.8070 - val_loss: 2.0364 - val_acc: 0.5112\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.5090 - acc: 0.8189 - val_loss: 2.1321 - val_acc: 0.5211\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.4903 - acc: 0.8254 - val_loss: 2.0937 - val_acc: 0.5169\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.4690 - acc: 0.8314 - val_loss: 2.1841 - val_acc: 0.5099\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.4437 - acc: 0.8423 - val_loss: 2.2858 - val_acc: 0.5115\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.4420 - acc: 0.8415 - val_loss: 2.3135 - val_acc: 0.5102\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.4290 - acc: 0.8461 - val_loss: 2.2681 - val_acc: 0.5036\n",
      "Experiment with LR = 0.000100\n",
      "Experiment with opt = <class 'keras.optimizers.SGD'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.3055 - acc: 0.1019 - val_loss: 2.3020 - val_acc: 0.1052\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2978 - acc: 0.1084 - val_loss: 2.2943 - val_acc: 0.1145\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2912 - acc: 0.1183 - val_loss: 2.2885 - val_acc: 0.1226\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2864 - acc: 0.1312 - val_loss: 2.2842 - val_acc: 0.1348\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2825 - acc: 0.1471 - val_loss: 2.2805 - val_acc: 0.1451\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2791 - acc: 0.1587 - val_loss: 2.2771 - val_acc: 0.1562\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2758 - acc: 0.1686 - val_loss: 2.2739 - val_acc: 0.1667\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2727 - acc: 0.1767 - val_loss: 2.2708 - val_acc: 0.1750\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2696 - acc: 0.1858 - val_loss: 2.2678 - val_acc: 0.1831\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2666 - acc: 0.1930 - val_loss: 2.2649 - val_acc: 0.1882\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2636 - acc: 0.2009 - val_loss: 2.2620 - val_acc: 0.1933\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2608 - acc: 0.2070 - val_loss: 2.2591 - val_acc: 0.1988\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 2.2580 - acc: 0.2102 - val_loss: 2.2563 - val_acc: 0.2026\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2552 - acc: 0.2142 - val_loss: 2.2537 - val_acc: 0.2060\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2525 - acc: 0.2167 - val_loss: 2.2510 - val_acc: 0.2096\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.2499 - acc: 0.2183 - val_loss: 2.2484 - val_acc: 0.2126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 2.2473 - acc: 0.2210 - val_loss: 2.2459 - val_acc: 0.2157\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2448 - acc: 0.2219 - val_loss: 2.2433 - val_acc: 0.2168\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2422 - acc: 0.2234 - val_loss: 2.2408 - val_acc: 0.2184\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2397 - acc: 0.2251 - val_loss: 2.2383 - val_acc: 0.2194\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2372 - acc: 0.2259 - val_loss: 2.2359 - val_acc: 0.2215\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2348 - acc: 0.2269 - val_loss: 2.2334 - val_acc: 0.2239\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2324 - acc: 0.2283 - val_loss: 2.2310 - val_acc: 0.2245\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2300 - acc: 0.2291 - val_loss: 2.2286 - val_acc: 0.2252\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2276 - acc: 0.2302 - val_loss: 2.2262 - val_acc: 0.2253\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2252 - acc: 0.2308 - val_loss: 2.2239 - val_acc: 0.2251\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2228 - acc: 0.2315 - val_loss: 2.2215 - val_acc: 0.2256\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 2.2205 - acc: 0.2319 - val_loss: 2.2192 - val_acc: 0.2267\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2181 - acc: 0.2324 - val_loss: 2.2168 - val_acc: 0.2275\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 2.2158 - acc: 0.2324 - val_loss: 2.2145 - val_acc: 0.2286\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2134 - acc: 0.2332 - val_loss: 2.2121 - val_acc: 0.2288\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2111 - acc: 0.2334 - val_loss: 2.2098 - val_acc: 0.2304\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2087 - acc: 0.2339 - val_loss: 2.2075 - val_acc: 0.2318\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2064 - acc: 0.2344 - val_loss: 2.2051 - val_acc: 0.2319\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2040 - acc: 0.2353 - val_loss: 2.2027 - val_acc: 0.2321\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2016 - acc: 0.2352 - val_loss: 2.2004 - val_acc: 0.2333\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.1992 - acc: 0.2362 - val_loss: 2.1980 - val_acc: 0.2336\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.1968 - acc: 0.2371 - val_loss: 2.1956 - val_acc: 0.2340\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.1944 - acc: 0.2376 - val_loss: 2.1931 - val_acc: 0.2348\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 2.1919 - acc: 0.2369 - val_loss: 2.1907 - val_acc: 0.2360\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 2.1895 - acc: 0.2381 - val_loss: 2.1882 - val_acc: 0.2369\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.1870 - acc: 0.2393 - val_loss: 2.1858 - val_acc: 0.2372\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.1845 - acc: 0.2392 - val_loss: 2.1833 - val_acc: 0.2387\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.1820 - acc: 0.2400 - val_loss: 2.1807 - val_acc: 0.2387\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.1795 - acc: 0.2411 - val_loss: 2.1782 - val_acc: 0.2389\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.1769 - acc: 0.2415 - val_loss: 2.1756 - val_acc: 0.2384\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.1743 - acc: 0.2420 - val_loss: 2.1730 - val_acc: 0.2393\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.1716 - acc: 0.2427 - val_loss: 2.1704 - val_acc: 0.2396\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.1690 - acc: 0.2425 - val_loss: 2.1677 - val_acc: 0.2420\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.1662 - acc: 0.2434 - val_loss: 2.1650 - val_acc: 0.2421\n",
      "Experiment with LR = 0.000100\n",
      "Experiment with opt = <class 'keras.optimizers.RMSprop'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 12s 239us/step - loss: 2.0739 - acc: 0.2355 - val_loss: 2.0100 - val_acc: 0.2660\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.8887 - acc: 0.3287 - val_loss: 1.8811 - val_acc: 0.3104\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.7848 - acc: 0.3669 - val_loss: 1.7200 - val_acc: 0.3972\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.7166 - acc: 0.3895 - val_loss: 1.7802 - val_acc: 0.3703\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.6648 - acc: 0.4078 - val_loss: 1.7437 - val_acc: 0.3808\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.6205 - acc: 0.4267 - val_loss: 1.6215 - val_acc: 0.4179\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.5817 - acc: 0.4384 - val_loss: 1.5844 - val_acc: 0.4368\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 1.5501 - acc: 0.4539 - val_loss: 1.6063 - val_acc: 0.4292\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.5216 - acc: 0.4630 - val_loss: 1.5936 - val_acc: 0.4288\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.4897 - acc: 0.4716 - val_loss: 1.5898 - val_acc: 0.4270\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 1.4636 - acc: 0.4806 - val_loss: 1.5395 - val_acc: 0.4553\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4412 - acc: 0.4883 - val_loss: 1.4773 - val_acc: 0.4635\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.4189 - acc: 0.4979 - val_loss: 1.4833 - val_acc: 0.4670\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.3971 - acc: 0.5066 - val_loss: 1.5888 - val_acc: 0.4495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.3743 - acc: 0.5133 - val_loss: 1.3954 - val_acc: 0.4986\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.3516 - acc: 0.5203 - val_loss: 1.4819 - val_acc: 0.4590\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.3299 - acc: 0.5301 - val_loss: 1.5083 - val_acc: 0.4608\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.3139 - acc: 0.5370 - val_loss: 1.4863 - val_acc: 0.4494\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 1.2928 - acc: 0.5426 - val_loss: 1.4884 - val_acc: 0.4724\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.2766 - acc: 0.5481 - val_loss: 1.4474 - val_acc: 0.4932\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.2559 - acc: 0.5566 - val_loss: 1.5748 - val_acc: 0.4571\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.2391 - acc: 0.5616 - val_loss: 1.4870 - val_acc: 0.4675\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.2238 - acc: 0.5686 - val_loss: 1.4154 - val_acc: 0.5010\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.2038 - acc: 0.5737 - val_loss: 1.4699 - val_acc: 0.4868\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.1855 - acc: 0.5800 - val_loss: 1.7048 - val_acc: 0.4332\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.1714 - acc: 0.5866 - val_loss: 1.3786 - val_acc: 0.5120\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.1504 - acc: 0.5941 - val_loss: 1.3514 - val_acc: 0.5179\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.1360 - acc: 0.6010 - val_loss: 1.5355 - val_acc: 0.4799\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.1150 - acc: 0.6067 - val_loss: 1.3662 - val_acc: 0.5187\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 1.1006 - acc: 0.6120 - val_loss: 1.3446 - val_acc: 0.5322\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.0821 - acc: 0.6192 - val_loss: 1.5493 - val_acc: 0.4655\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.0651 - acc: 0.6263 - val_loss: 1.4273 - val_acc: 0.4962\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.0521 - acc: 0.6311 - val_loss: 1.3744 - val_acc: 0.5183\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.0356 - acc: 0.6373 - val_loss: 1.3692 - val_acc: 0.5214\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.0222 - acc: 0.6397 - val_loss: 1.4292 - val_acc: 0.5127\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.9986 - acc: 0.6459 - val_loss: 1.4136 - val_acc: 0.5193\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.9892 - acc: 0.6531 - val_loss: 1.3361 - val_acc: 0.5371\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.9682 - acc: 0.6584 - val_loss: 1.4364 - val_acc: 0.5117\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.9469 - acc: 0.6657 - val_loss: 1.4372 - val_acc: 0.5170\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.9352 - acc: 0.6724 - val_loss: 1.4098 - val_acc: 0.5161\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.9181 - acc: 0.6761 - val_loss: 1.3730 - val_acc: 0.5326\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.9012 - acc: 0.6834 - val_loss: 1.4251 - val_acc: 0.5149\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.8943 - acc: 0.6862 - val_loss: 1.4116 - val_acc: 0.5259\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 0.8715 - acc: 0.6958 - val_loss: 1.4322 - val_acc: 0.5232\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.8572 - acc: 0.6990 - val_loss: 1.4216 - val_acc: 0.5307\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 0.8385 - acc: 0.7053 - val_loss: 1.3860 - val_acc: 0.5339\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.8255 - acc: 0.7087 - val_loss: 1.5797 - val_acc: 0.4985\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.8103 - acc: 0.7161 - val_loss: 1.4302 - val_acc: 0.5314\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.7962 - acc: 0.7215 - val_loss: 1.5791 - val_acc: 0.5001\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 0.7785 - acc: 0.7261 - val_loss: 1.5529 - val_acc: 0.5245\n",
      "Experiment with LR = 0.000100\n",
      "Experiment with opt = <class 'keras.optimizers.Adagrad'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 2.1226 - acc: 0.2663 - val_loss: 2.0492 - val_acc: 0.2817\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.9990 - acc: 0.3045 - val_loss: 1.9650 - val_acc: 0.3188\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.9413 - acc: 0.3225 - val_loss: 1.9212 - val_acc: 0.3308\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.9022 - acc: 0.3359 - val_loss: 1.8886 - val_acc: 0.3439\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.8719 - acc: 0.3490 - val_loss: 1.8734 - val_acc: 0.3458\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.8475 - acc: 0.3599 - val_loss: 1.8427 - val_acc: 0.3612\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.8254 - acc: 0.3679 - val_loss: 1.8228 - val_acc: 0.3657\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.8067 - acc: 0.3766 - val_loss: 1.8025 - val_acc: 0.3774\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.7903 - acc: 0.3840 - val_loss: 1.7888 - val_acc: 0.3899\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.7757 - acc: 0.3894 - val_loss: 1.7773 - val_acc: 0.3913\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.7632 - acc: 0.3921 - val_loss: 1.7672 - val_acc: 0.3928\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.7519 - acc: 0.3955 - val_loss: 1.7547 - val_acc: 0.3984\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.7413 - acc: 0.3995 - val_loss: 1.7460 - val_acc: 0.3994\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.7322 - acc: 0.4024 - val_loss: 1.7397 - val_acc: 0.3993\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.7237 - acc: 0.4047 - val_loss: 1.7297 - val_acc: 0.4003\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.7155 - acc: 0.4088 - val_loss: 1.7214 - val_acc: 0.4071\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.7080 - acc: 0.4115 - val_loss: 1.7142 - val_acc: 0.4083\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.7006 - acc: 0.4137 - val_loss: 1.7114 - val_acc: 0.4066\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.6943 - acc: 0.4153 - val_loss: 1.7025 - val_acc: 0.4135\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6882 - acc: 0.4167 - val_loss: 1.6984 - val_acc: 0.4128\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6824 - acc: 0.4195 - val_loss: 1.6926 - val_acc: 0.4150\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6769 - acc: 0.4211 - val_loss: 1.6862 - val_acc: 0.4166\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6713 - acc: 0.4230 - val_loss: 1.6803 - val_acc: 0.4176\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.6664 - acc: 0.4231 - val_loss: 1.6776 - val_acc: 0.4176\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6614 - acc: 0.4260 - val_loss: 1.6731 - val_acc: 0.4227\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6567 - acc: 0.4275 - val_loss: 1.6684 - val_acc: 0.4187\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6520 - acc: 0.4289 - val_loss: 1.6652 - val_acc: 0.4194\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6482 - acc: 0.4309 - val_loss: 1.6611 - val_acc: 0.4215\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6443 - acc: 0.4310 - val_loss: 1.6579 - val_acc: 0.4245\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6401 - acc: 0.4327 - val_loss: 1.6564 - val_acc: 0.4235\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6364 - acc: 0.4343 - val_loss: 1.6519 - val_acc: 0.4253\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6328 - acc: 0.4355 - val_loss: 1.6489 - val_acc: 0.4255\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 1.6293 - acc: 0.4365 - val_loss: 1.6478 - val_acc: 0.4230\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6261 - acc: 0.4363 - val_loss: 1.6425 - val_acc: 0.4311\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6226 - acc: 0.4387 - val_loss: 1.6422 - val_acc: 0.4285\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6196 - acc: 0.4388 - val_loss: 1.6376 - val_acc: 0.4280\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6166 - acc: 0.4410 - val_loss: 1.6345 - val_acc: 0.4303\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6136 - acc: 0.4416 - val_loss: 1.6310 - val_acc: 0.4333\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6106 - acc: 0.4424 - val_loss: 1.6294 - val_acc: 0.4330\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6079 - acc: 0.4430 - val_loss: 1.6284 - val_acc: 0.4316\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6051 - acc: 0.4446 - val_loss: 1.6232 - val_acc: 0.4345\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.6028 - acc: 0.4448 - val_loss: 1.6213 - val_acc: 0.4369\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6001 - acc: 0.4458 - val_loss: 1.6183 - val_acc: 0.4365\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.5975 - acc: 0.4459 - val_loss: 1.6176 - val_acc: 0.4359\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.5949 - acc: 0.4476 - val_loss: 1.6168 - val_acc: 0.4378\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.5925 - acc: 0.4482 - val_loss: 1.6140 - val_acc: 0.4386\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.5903 - acc: 0.4489 - val_loss: 1.6107 - val_acc: 0.4386\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.5878 - acc: 0.4501 - val_loss: 1.6111 - val_acc: 0.4385\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.5858 - acc: 0.4510 - val_loss: 1.6074 - val_acc: 0.4408\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.5836 - acc: 0.4512 - val_loss: 1.6065 - val_acc: 0.4380\n",
      "Experiment with LR = 0.000100\n",
      "Experiment with opt = <class 'keras.optimizers.Adam'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 1.9872 - acc: 0.2822 - val_loss: 1.8508 - val_acc: 0.3392\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.7668 - acc: 0.3690 - val_loss: 1.7074 - val_acc: 0.3862\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.6667 - acc: 0.4108 - val_loss: 1.6211 - val_acc: 0.4307\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.6042 - acc: 0.4343 - val_loss: 1.5607 - val_acc: 0.4521\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.5601 - acc: 0.4507 - val_loss: 1.5777 - val_acc: 0.4532\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.5226 - acc: 0.4610 - val_loss: 1.5459 - val_acc: 0.4492\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4814 - acc: 0.4757 - val_loss: 1.5279 - val_acc: 0.4560\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.4515 - acc: 0.4864 - val_loss: 1.4855 - val_acc: 0.4677\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4179 - acc: 0.4984 - val_loss: 1.4547 - val_acc: 0.4861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3975 - acc: 0.5046 - val_loss: 1.4462 - val_acc: 0.4855\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.3573 - acc: 0.5204 - val_loss: 1.4499 - val_acc: 0.4879\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.3352 - acc: 0.5277 - val_loss: 1.4096 - val_acc: 0.5013\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.3160 - acc: 0.5374 - val_loss: 1.3949 - val_acc: 0.5042\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.2893 - acc: 0.5449 - val_loss: 1.4008 - val_acc: 0.5088\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.2654 - acc: 0.5514 - val_loss: 1.3778 - val_acc: 0.5092\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 1.2417 - acc: 0.5618 - val_loss: 1.3694 - val_acc: 0.5100\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.2175 - acc: 0.5703 - val_loss: 1.4175 - val_acc: 0.5004\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.2035 - acc: 0.5758 - val_loss: 1.3907 - val_acc: 0.5111\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.1764 - acc: 0.5853 - val_loss: 1.3429 - val_acc: 0.5264\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.1562 - acc: 0.5914 - val_loss: 1.4122 - val_acc: 0.5047\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.1347 - acc: 0.6007 - val_loss: 1.3359 - val_acc: 0.5274\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.1149 - acc: 0.6076 - val_loss: 1.3456 - val_acc: 0.5270\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.0921 - acc: 0.6159 - val_loss: 1.3537 - val_acc: 0.5203\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.0723 - acc: 0.6232 - val_loss: 1.3943 - val_acc: 0.5172\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.0470 - acc: 0.6338 - val_loss: 1.3437 - val_acc: 0.5304\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.0259 - acc: 0.6410 - val_loss: 1.3304 - val_acc: 0.5389\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.0095 - acc: 0.6483 - val_loss: 1.3762 - val_acc: 0.5174\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.9888 - acc: 0.6528 - val_loss: 1.3812 - val_acc: 0.5205\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.9664 - acc: 0.6591 - val_loss: 1.3726 - val_acc: 0.5303\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.9495 - acc: 0.6674 - val_loss: 1.3467 - val_acc: 0.5383\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.9272 - acc: 0.6727 - val_loss: 1.3430 - val_acc: 0.5363\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.9104 - acc: 0.6819 - val_loss: 1.3506 - val_acc: 0.5408\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.8865 - acc: 0.6892 - val_loss: 1.3571 - val_acc: 0.5420\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.8710 - acc: 0.6952 - val_loss: 1.4138 - val_acc: 0.5326\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.8530 - acc: 0.7042 - val_loss: 1.4047 - val_acc: 0.5283\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.8333 - acc: 0.7084 - val_loss: 1.4039 - val_acc: 0.5351\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.8088 - acc: 0.7188 - val_loss: 1.3913 - val_acc: 0.5407\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 0.7864 - acc: 0.7266 - val_loss: 1.4290 - val_acc: 0.5366\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.7819 - acc: 0.7272 - val_loss: 1.4293 - val_acc: 0.5325\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.7547 - acc: 0.7385 - val_loss: 1.4231 - val_acc: 0.5429\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.7430 - acc: 0.7405 - val_loss: 1.4436 - val_acc: 0.5384\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.7233 - acc: 0.7499 - val_loss: 1.4383 - val_acc: 0.5396\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.7031 - acc: 0.7561 - val_loss: 1.5197 - val_acc: 0.5343\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.6864 - acc: 0.7620 - val_loss: 1.5423 - val_acc: 0.5300\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.6692 - acc: 0.7657 - val_loss: 1.5179 - val_acc: 0.5355\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.6517 - acc: 0.7738 - val_loss: 1.5337 - val_acc: 0.5356\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.6356 - acc: 0.7798 - val_loss: 1.5280 - val_acc: 0.5305\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.6170 - acc: 0.7874 - val_loss: 1.5279 - val_acc: 0.5438\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.5982 - acc: 0.7939 - val_loss: 1.5649 - val_acc: 0.5421\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.5715 - acc: 0.8028 - val_loss: 1.6529 - val_acc: 0.5258\n",
      "Experiment with LR = 0.000010\n",
      "Experiment with opt = <class 'keras.optimizers.SGD'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.3273 - acc: 0.0996 - val_loss: 2.3250 - val_acc: 0.0977\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.3255 - acc: 0.1005 - val_loss: 2.3233 - val_acc: 0.0990\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3238 - acc: 0.1014 - val_loss: 2.3216 - val_acc: 0.1006\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3223 - acc: 0.1023 - val_loss: 2.3201 - val_acc: 0.1020\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 2.3208 - acc: 0.1036 - val_loss: 2.3187 - val_acc: 0.1030\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3194 - acc: 0.1046 - val_loss: 2.3173 - val_acc: 0.1032\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3181 - acc: 0.1054 - val_loss: 2.3160 - val_acc: 0.1045\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3169 - acc: 0.1060 - val_loss: 2.3149 - val_acc: 0.1045\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.3158 - acc: 0.1070 - val_loss: 2.3138 - val_acc: 0.1051\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3147 - acc: 0.1072 - val_loss: 2.3128 - val_acc: 0.1054\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.3138 - acc: 0.1074 - val_loss: 2.3118 - val_acc: 0.1055\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.3128 - acc: 0.1074 - val_loss: 2.3109 - val_acc: 0.1065\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3120 - acc: 0.1084 - val_loss: 2.3101 - val_acc: 0.1062\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.3112 - acc: 0.1083 - val_loss: 2.3092 - val_acc: 0.1070\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3104 - acc: 0.1084 - val_loss: 2.3085 - val_acc: 0.1065\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3097 - acc: 0.1086 - val_loss: 2.3078 - val_acc: 0.1064\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3090 - acc: 0.1094 - val_loss: 2.3071 - val_acc: 0.1059\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.3083 - acc: 0.1095 - val_loss: 2.3065 - val_acc: 0.1067\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.3077 - acc: 0.1099 - val_loss: 2.3059 - val_acc: 0.1083\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.3071 - acc: 0.1102 - val_loss: 2.3053 - val_acc: 0.1098\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3066 - acc: 0.1108 - val_loss: 2.3047 - val_acc: 0.1107\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.3060 - acc: 0.1109 - val_loss: 2.3042 - val_acc: 0.1116\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3055 - acc: 0.1115 - val_loss: 2.3037 - val_acc: 0.1112\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3050 - acc: 0.1118 - val_loss: 2.3032 - val_acc: 0.1107\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.3046 - acc: 0.1124 - val_loss: 2.3028 - val_acc: 0.1118\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3041 - acc: 0.1127 - val_loss: 2.3023 - val_acc: 0.1129\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3037 - acc: 0.1133 - val_loss: 2.3019 - val_acc: 0.1147\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3033 - acc: 0.1138 - val_loss: 2.3015 - val_acc: 0.1148\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.3029 - acc: 0.1148 - val_loss: 2.3011 - val_acc: 0.1157\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3025 - acc: 0.1150 - val_loss: 2.3007 - val_acc: 0.1174\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3021 - acc: 0.1159 - val_loss: 2.3003 - val_acc: 0.1182\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.3018 - acc: 0.1163 - val_loss: 2.3000 - val_acc: 0.1178\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3014 - acc: 0.1169 - val_loss: 2.2996 - val_acc: 0.1189\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.3011 - acc: 0.1175 - val_loss: 2.2993 - val_acc: 0.1184\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3007 - acc: 0.1184 - val_loss: 2.2990 - val_acc: 0.1188\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3004 - acc: 0.1189 - val_loss: 2.2986 - val_acc: 0.1200\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.3001 - acc: 0.1195 - val_loss: 2.2983 - val_acc: 0.1204\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2998 - acc: 0.1200 - val_loss: 2.2980 - val_acc: 0.1207\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2995 - acc: 0.1201 - val_loss: 2.2977 - val_acc: 0.1215\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.2992 - acc: 0.1208 - val_loss: 2.2975 - val_acc: 0.1215\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.2989 - acc: 0.1210 - val_loss: 2.2972 - val_acc: 0.1217\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.2986 - acc: 0.1220 - val_loss: 2.2969 - val_acc: 0.1231\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2984 - acc: 0.1224 - val_loss: 2.2967 - val_acc: 0.1234\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2981 - acc: 0.1232 - val_loss: 2.2964 - val_acc: 0.1245\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 2.2978 - acc: 0.1231 - val_loss: 2.2962 - val_acc: 0.1250\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.2976 - acc: 0.1233 - val_loss: 2.2959 - val_acc: 0.1254\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2973 - acc: 0.1239 - val_loss: 2.2957 - val_acc: 0.1248\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2971 - acc: 0.1241 - val_loss: 2.2954 - val_acc: 0.1251\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2968 - acc: 0.1246 - val_loss: 2.2952 - val_acc: 0.1256\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 2.2966 - acc: 0.1250 - val_loss: 2.2950 - val_acc: 0.1264\n",
      "Experiment with LR = 0.000010\n",
      "Experiment with opt = <class 'keras.optimizers.RMSprop'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 12s 240us/step - loss: 2.1538 - acc: 0.2141 - val_loss: 2.0580 - val_acc: 0.2514\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 2.0093 - acc: 0.2701 - val_loss: 1.9796 - val_acc: 0.2814\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.9424 - acc: 0.2973 - val_loss: 1.9196 - val_acc: 0.3086\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.8937 - acc: 0.3178 - val_loss: 1.8702 - val_acc: 0.3279\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 12s 235us/step - loss: 1.8536 - acc: 0.3378 - val_loss: 1.8455 - val_acc: 0.3352\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.8200 - acc: 0.3521 - val_loss: 1.8115 - val_acc: 0.3572\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.7903 - acc: 0.3636 - val_loss: 1.7787 - val_acc: 0.3761\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.7650 - acc: 0.3754 - val_loss: 1.7565 - val_acc: 0.3896\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.7413 - acc: 0.3869 - val_loss: 1.7505 - val_acc: 0.3838\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.7205 - acc: 0.3933 - val_loss: 1.7382 - val_acc: 0.3829\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.7012 - acc: 0.4009 - val_loss: 1.7212 - val_acc: 0.3932\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 1.6834 - acc: 0.4085 - val_loss: 1.6870 - val_acc: 0.4062\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.6664 - acc: 0.4160 - val_loss: 1.6729 - val_acc: 0.4060\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.6513 - acc: 0.4214 - val_loss: 1.6922 - val_acc: 0.4084\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.6377 - acc: 0.4252 - val_loss: 1.6527 - val_acc: 0.4161\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.6228 - acc: 0.4331 - val_loss: 1.6325 - val_acc: 0.4289\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.6108 - acc: 0.4369 - val_loss: 1.6216 - val_acc: 0.4301\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.5987 - acc: 0.4385 - val_loss: 1.6245 - val_acc: 0.4303\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.5869 - acc: 0.4443 - val_loss: 1.6098 - val_acc: 0.4284\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.5750 - acc: 0.4488 - val_loss: 1.6193 - val_acc: 0.4336\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.5641 - acc: 0.4524 - val_loss: 1.5825 - val_acc: 0.4481\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.5556 - acc: 0.4556 - val_loss: 1.5723 - val_acc: 0.4475\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.5439 - acc: 0.4613 - val_loss: 1.5928 - val_acc: 0.4359\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.5347 - acc: 0.4620 - val_loss: 1.5612 - val_acc: 0.4494\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.5249 - acc: 0.4670 - val_loss: 1.5491 - val_acc: 0.4528\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.5160 - acc: 0.4684 - val_loss: 1.5772 - val_acc: 0.4362\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.5088 - acc: 0.4722 - val_loss: 1.5740 - val_acc: 0.4394\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4996 - acc: 0.4732 - val_loss: 1.5644 - val_acc: 0.4416\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.4927 - acc: 0.4771 - val_loss: 1.5774 - val_acc: 0.4439\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4841 - acc: 0.4781 - val_loss: 1.5371 - val_acc: 0.4542\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4769 - acc: 0.4835 - val_loss: 1.5586 - val_acc: 0.4364\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4698 - acc: 0.4837 - val_loss: 1.5556 - val_acc: 0.4543\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.4630 - acc: 0.4847 - val_loss: 1.4998 - val_acc: 0.4674\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4556 - acc: 0.4874 - val_loss: 1.5140 - val_acc: 0.4671\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4476 - acc: 0.4911 - val_loss: 1.5421 - val_acc: 0.4633\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4423 - acc: 0.4935 - val_loss: 1.4924 - val_acc: 0.4699\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4348 - acc: 0.4955 - val_loss: 1.4754 - val_acc: 0.4767\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4293 - acc: 0.4981 - val_loss: 1.5641 - val_acc: 0.4358\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4244 - acc: 0.4986 - val_loss: 1.4818 - val_acc: 0.4800\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.4161 - acc: 0.5029 - val_loss: 1.4771 - val_acc: 0.4724\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4106 - acc: 0.5048 - val_loss: 1.5316 - val_acc: 0.4568\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4044 - acc: 0.5064 - val_loss: 1.4623 - val_acc: 0.4830\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4011 - acc: 0.5074 - val_loss: 1.4998 - val_acc: 0.4614\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.3938 - acc: 0.5084 - val_loss: 1.4934 - val_acc: 0.4701\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.3893 - acc: 0.5118 - val_loss: 1.4766 - val_acc: 0.4744\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.3833 - acc: 0.5128 - val_loss: 1.4432 - val_acc: 0.4885\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.3785 - acc: 0.5166 - val_loss: 1.4446 - val_acc: 0.4879\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.3709 - acc: 0.5161 - val_loss: 1.4720 - val_acc: 0.4775\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.3666 - acc: 0.5199 - val_loss: 1.4477 - val_acc: 0.4943\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.3632 - acc: 0.5191 - val_loss: 1.4513 - val_acc: 0.4789\n",
      "Experiment with LR = 0.000010\n",
      "Experiment with opt = <class 'keras.optimizers.Adagrad'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 2.2577 - acc: 0.1713 - val_loss: 2.2335 - val_acc: 0.1854\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.2222 - acc: 0.1991 - val_loss: 2.2108 - val_acc: 0.2040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.2039 - acc: 0.2084 - val_loss: 2.1959 - val_acc: 0.2082\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 2.1908 - acc: 0.2125 - val_loss: 2.1844 - val_acc: 0.2148\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.1804 - acc: 0.2153 - val_loss: 2.1749 - val_acc: 0.2190\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 2.1715 - acc: 0.2188 - val_loss: 2.1666 - val_acc: 0.2271\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.1636 - acc: 0.2233 - val_loss: 2.1591 - val_acc: 0.2293\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.1565 - acc: 0.2266 - val_loss: 2.1523 - val_acc: 0.2342\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.1499 - acc: 0.2299 - val_loss: 2.1460 - val_acc: 0.2355\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.1439 - acc: 0.2342 - val_loss: 2.1403 - val_acc: 0.2390\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 2.1384 - acc: 0.2369 - val_loss: 2.1350 - val_acc: 0.2426\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.1333 - acc: 0.2402 - val_loss: 2.1301 - val_acc: 0.2462\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.1286 - acc: 0.2425 - val_loss: 2.1255 - val_acc: 0.2513\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.1241 - acc: 0.2460 - val_loss: 2.1212 - val_acc: 0.2517\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.1199 - acc: 0.2492 - val_loss: 2.1171 - val_acc: 0.2537\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.1159 - acc: 0.2504 - val_loss: 2.1132 - val_acc: 0.2575\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.1122 - acc: 0.2536 - val_loss: 2.1096 - val_acc: 0.2597\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.1086 - acc: 0.2564 - val_loss: 2.1061 - val_acc: 0.2611\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.1051 - acc: 0.2577 - val_loss: 2.1027 - val_acc: 0.2629\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.1018 - acc: 0.2597 - val_loss: 2.0994 - val_acc: 0.2657\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0986 - acc: 0.2620 - val_loss: 2.0963 - val_acc: 0.2673\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0955 - acc: 0.2638 - val_loss: 2.0932 - val_acc: 0.2684\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0925 - acc: 0.2656 - val_loss: 2.0903 - val_acc: 0.2693\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0895 - acc: 0.2666 - val_loss: 2.0875 - val_acc: 0.2721\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0867 - acc: 0.2691 - val_loss: 2.0848 - val_acc: 0.2729\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0840 - acc: 0.2704 - val_loss: 2.0822 - val_acc: 0.2740\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0813 - acc: 0.2719 - val_loss: 2.0796 - val_acc: 0.2751\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0787 - acc: 0.2734 - val_loss: 2.0771 - val_acc: 0.2747\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0762 - acc: 0.2746 - val_loss: 2.0746 - val_acc: 0.2767\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0737 - acc: 0.2756 - val_loss: 2.0723 - val_acc: 0.2776\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0712 - acc: 0.2769 - val_loss: 2.0700 - val_acc: 0.2777\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0688 - acc: 0.2775 - val_loss: 2.0677 - val_acc: 0.2786\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0665 - acc: 0.2781 - val_loss: 2.0655 - val_acc: 0.2792\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0643 - acc: 0.2793 - val_loss: 2.0633 - val_acc: 0.2810\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0620 - acc: 0.2807 - val_loss: 2.0612 - val_acc: 0.2805\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0599 - acc: 0.2810 - val_loss: 2.0591 - val_acc: 0.2845\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0577 - acc: 0.2829 - val_loss: 2.0571 - val_acc: 0.2848\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 2.0557 - acc: 0.2835 - val_loss: 2.0551 - val_acc: 0.2844\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0536 - acc: 0.2844 - val_loss: 2.0531 - val_acc: 0.2858\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 2.0516 - acc: 0.2855 - val_loss: 2.0512 - val_acc: 0.2869\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0497 - acc: 0.2866 - val_loss: 2.0494 - val_acc: 0.2877\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0478 - acc: 0.2868 - val_loss: 2.0476 - val_acc: 0.2877\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 2.0459 - acc: 0.2880 - val_loss: 2.0458 - val_acc: 0.2886\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0441 - acc: 0.2881 - val_loss: 2.0441 - val_acc: 0.2882\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0424 - acc: 0.2890 - val_loss: 2.0424 - val_acc: 0.2896\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0406 - acc: 0.2899 - val_loss: 2.0408 - val_acc: 0.2901\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0389 - acc: 0.2898 - val_loss: 2.0391 - val_acc: 0.2920\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0372 - acc: 0.2908 - val_loss: 2.0376 - val_acc: 0.2921\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.0356 - acc: 0.2914 - val_loss: 2.0360 - val_acc: 0.2921\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0340 - acc: 0.2918 - val_loss: 2.0345 - val_acc: 0.2926\n",
      "Experiment with LR = 0.000010\n",
      "Experiment with opt = <class 'keras.optimizers.Adam'> \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer6 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,846,442\n",
      "Trainable params: 3,846,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 2.1777 - acc: 0.1915 - val_loss: 2.0745 - val_acc: 0.2312\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 2.0139 - acc: 0.2548 - val_loss: 1.9604 - val_acc: 0.2835\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.9206 - acc: 0.3046 - val_loss: 1.8872 - val_acc: 0.3257\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.8520 - acc: 0.3423 - val_loss: 1.8320 - val_acc: 0.3448\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.7991 - acc: 0.3705 - val_loss: 1.7826 - val_acc: 0.3823\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.7588 - acc: 0.3857 - val_loss: 1.7472 - val_acc: 0.3961\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.7249 - acc: 0.3977 - val_loss: 1.7154 - val_acc: 0.4011\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.6929 - acc: 0.4100 - val_loss: 1.6895 - val_acc: 0.4063\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.6688 - acc: 0.4160 - val_loss: 1.6681 - val_acc: 0.4193\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 1.6473 - acc: 0.4234 - val_loss: 1.6531 - val_acc: 0.4255\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.6263 - acc: 0.4325 - val_loss: 1.6315 - val_acc: 0.4321\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.6094 - acc: 0.4380 - val_loss: 1.6276 - val_acc: 0.4255\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.5928 - acc: 0.4419 - val_loss: 1.6052 - val_acc: 0.4360\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.5795 - acc: 0.4472 - val_loss: 1.5970 - val_acc: 0.4420\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 1.5652 - acc: 0.4512 - val_loss: 1.5790 - val_acc: 0.4465\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 1.5502 - acc: 0.4570 - val_loss: 1.5690 - val_acc: 0.4459\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.5402 - acc: 0.4626 - val_loss: 1.5565 - val_acc: 0.4518\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.5284 - acc: 0.4629 - val_loss: 1.5478 - val_acc: 0.4515\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.5155 - acc: 0.4701 - val_loss: 1.5745 - val_acc: 0.4369\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.5053 - acc: 0.4729 - val_loss: 1.5352 - val_acc: 0.4623\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4951 - acc: 0.4746 - val_loss: 1.5275 - val_acc: 0.4581\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4854 - acc: 0.4801 - val_loss: 1.5164 - val_acc: 0.4630\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4737 - acc: 0.4836 - val_loss: 1.5154 - val_acc: 0.4673\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4664 - acc: 0.4867 - val_loss: 1.5017 - val_acc: 0.4677\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.4559 - acc: 0.4907 - val_loss: 1.4998 - val_acc: 0.4682\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4505 - acc: 0.4916 - val_loss: 1.4988 - val_acc: 0.4725\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4405 - acc: 0.4953 - val_loss: 1.4819 - val_acc: 0.4777\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4349 - acc: 0.4976 - val_loss: 1.4723 - val_acc: 0.4811\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.4244 - acc: 0.4993 - val_loss: 1.4997 - val_acc: 0.4703\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4168 - acc: 0.5036 - val_loss: 1.4747 - val_acc: 0.4808\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4089 - acc: 0.5071 - val_loss: 1.4732 - val_acc: 0.4831\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4011 - acc: 0.5079 - val_loss: 1.4614 - val_acc: 0.4826\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3936 - acc: 0.5117 - val_loss: 1.4585 - val_acc: 0.4839\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3855 - acc: 0.5144 - val_loss: 1.4550 - val_acc: 0.4888\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3792 - acc: 0.5163 - val_loss: 1.4431 - val_acc: 0.4918\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3713 - acc: 0.5200 - val_loss: 1.4404 - val_acc: 0.4937\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3666 - acc: 0.5208 - val_loss: 1.4398 - val_acc: 0.4902\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3594 - acc: 0.5223 - val_loss: 1.4322 - val_acc: 0.4892\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3505 - acc: 0.5258 - val_loss: 1.4282 - val_acc: 0.4919\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3455 - acc: 0.5268 - val_loss: 1.4300 - val_acc: 0.4921\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3413 - acc: 0.5285 - val_loss: 1.4262 - val_acc: 0.4953\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3330 - acc: 0.5333 - val_loss: 1.4202 - val_acc: 0.5015\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.3308 - acc: 0.5326 - val_loss: 1.4191 - val_acc: 0.5033\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3208 - acc: 0.5351 - val_loss: 1.4128 - val_acc: 0.5020\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3196 - acc: 0.5370 - val_loss: 1.4124 - val_acc: 0.5031\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3109 - acc: 0.5392 - val_loss: 1.4046 - val_acc: 0.5050\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3037 - acc: 0.5423 - val_loss: 1.4076 - val_acc: 0.5010\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.2967 - acc: 0.5445 - val_loss: 1.3955 - val_acc: 0.5056\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.2939 - acc: 0.5447 - val_loss: 1.4025 - val_acc: 0.5073\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 1.2870 - acc: 0.5476 - val_loss: 1.3972 - val_acc: 0.5049\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from itertools import *\n",
    "results = {}\n",
    "\"\"\"\n",
    "建立你的訓練與實驗迴圈並蒐集資料\n",
    "\"\"\"\n",
    "for lr , opt in itertools.product(LEARNING_RATE, OPTIMIZERS):\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with LR = %.6f\" % (lr))\n",
    "    print(\"Experiment with opt = %s \" % str(opt))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    #optimizer = keras.optimizers.SGD(lr=lr, nesterov=True, momentum=MOMENTUM)\n",
    "    opt = opt(lr=lr)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=opt)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"acc\"]\n",
    "    valid_acc = model.history.history[\"val_acc\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-lr-%s\" % str(lr)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"\n",
    "將實驗結果繪出\n",
    "\"\"\"\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
